# Gemma 7B - lLama3 8B - Gemma2 9B - Instruct   Colab

In this repository you can find a basic implementation of llamacpp python with a gradio UI, I wanted to use the standard completions api instead of the new chat_completions one.
It's simple but it can be useful for when you are not near your workstation and you need to show how those small models manage different kinds of questions/tasks.

## How to use
Just follow the notebook instructions
-   Run [`LLM_Gemma7b_Gemma2_9b_Llama3_8b-IT.ipynb`]
[![Open In Colab][colabicon]]

[colabicon]: <https://colab.research.google.com/assets/colab-badge.svg>


